# ğŸ“Š AgentBox Telemetry Dashboard

Real-time observability dashboard for AgentBox (OpenClaw) sessions, featuring LLM usage tracking, token analysis, cost monitoring, and tool analytics.

![AgentBox Telemetry Dashboard](https://img.shields.io/badge/Status-Production-green)
![Python](https://img.shields.io/badge/Python-3.10+-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ¯ What is This?

The AgentBox Telemetry Dashboard provides production-grade observability for your AI agent deployment:

âœ… **Real-time cost tracking** across all sessions and models  
âœ… **Token usage analytics** with cache optimization insights  
âœ… **Tool usage patterns** to identify bottlenecks  
âœ… **Timeline visualization** of agent activity  
âœ… **Session-level breakdowns** for debugging expensive runs  

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd telemetry
pip install -r requirements.txt
```

Or use a virtual environment (recommended):

```bash
cd telemetry
python3 -m venv .venv
source .venv/bin/activate  # Linux/macOS
# or
.venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### 2. Start the Dashboard

```bash
# From the telemetry directory
./start.sh

# Or manually:
streamlit run dashboard.py --server.port 8501 --server.address 0.0.0.0
```

### 3. Access the Dashboard

Open your browser to: **http://localhost:8501**

The dashboard will automatically discover and load OpenClaw session logs from:
- `/tmp/openclaw/` (default OpenClaw log directory)
- `~/.openclaw/` (alternative location)
- Or specify custom path in the UI

## ğŸ“Š Dashboard Features

### Overview Metrics
- Total sessions, messages, and tool calls
- Aggregate token counts (input, output, cache read/write)
- Total API costs across all models

### Timeline Visualization
- Usage patterns (hourly, daily, monthly)
- Cost trends and spike detection
- Message volume tracking

### Model Analytics
- Per-model cost breakdown
- Token distribution by provider
- Session count by model
- Cost distribution charts

### Tool Usage Tracking
- Most frequently used tools
- Tool call patterns
- Performance insights

### Session History
- Recent session details
- Per-session token and cost data
- Cron job and sub-agent tracking

## ğŸ³ Running in Docker

### Option 1: Docker Compose (Recommended)

Add this to your `docker-compose.yml`:

```yaml
version: '3.8'
services:
  agentbox:
    build: .
    volumes:
      - agentbox-data:/agentbox/data
      - agentbox-logs:/tmp/openclaw  # Share logs with telemetry
    ports:
      - "127.0.0.1:3000:3000"
  
  telemetry:
    build: ./telemetry
    volumes:
      - agentbox-logs:/tmp/openclaw:ro  # Read-only access to logs
    ports:
      - "127.0.0.1:8501:8501"
    depends_on:
      - agentbox

volumes:
  agentbox-data:
  agentbox-logs:
```

Then start both services:

```bash
docker-compose up -d
```

### Option 2: Standalone Docker Container

```bash
# Build the telemetry image
cd telemetry
docker build -t agentbox-telemetry .

# Run the container
docker run -d --name telemetry \
  -v /tmp/openclaw:/tmp/openclaw:ro \
  -p 127.0.0.1:8501:8501 \
  agentbox-telemetry
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# OpenClaw log directory (default: /tmp/openclaw)
export OPENCLAW_LOG_DIR=/path/to/openclaw/logs

# Streamlit port (default: 8501)
export STREAMLIT_PORT=8501

# Streamlit address (default: 0.0.0.0)
export STREAMLIT_ADDRESS=0.0.0.0
```

### Custom Log Directory

If your OpenClaw logs are in a different location:

1. **Via UI**: Use the sidebar "Select Log Directory" dropdown
2. **Via Script**: Edit `dashboard.py` and update `LOG_DIRS` list
3. **Via Environment**: Set `OPENCLAW_LOG_DIR` environment variable

## ğŸ“ˆ Understanding the Metrics

### Token Metrics

- **Input Tokens**: Tokens sent to the model (prompts, context)
- **Output Tokens**: Tokens generated by the model (responses)
- **Cache Read**: Tokens loaded from prompt cache (cheap!)
- **Cache Write**: Tokens written to prompt cache (one-time cost)

**Tip**: High cache read rates mean you're saving money! ğŸ’°

### Cost Calculation

Costs are calculated using model-specific pricing:
- Claude Opus 4: $15/$75 per 1M tokens (input/output)
- Claude Sonnet 4.5: $3/$15 per 1M tokens
- GPT-4: $10/$30 per 1M tokens
- GPT-3.5: $0.50/$1.50 per 1M tokens

**Note**: Prices are estimates and may vary. Check your provider for exact pricing.

### Tool Usage

Tool calls tracked include:
- `exec` - Shell command execution
- `web_search` - Web searches
- `browser` - Browser automation
- `Read`, `Write`, `Edit` - File operations
- And many more...

## ğŸš¨ Alerts & Monitoring

### Built-in Alerts

- **High Session Cost**: Alerts when a single session exceeds $1
- **High Token Usage**: Alerts when a session uses >100k tokens
- **Cost Spikes**: Detects unusual spending patterns

### Custom Alerts

To add custom alert rules, edit `dashboard.py`:

```python
# Add to the alerts section
if session_cost > YOUR_THRESHOLD:
    st.warning(f"âš ï¸ Session exceeded ${YOUR_THRESHOLD}")
```

## ğŸ”’ Security Considerations

### Production Deployment

When exposing the dashboard externally:

1. **Use Authentication**: Add Streamlit authentication
   ```bash
   streamlit run dashboard.py --server.enableCORS=false --server.enableXsrfProtection=true
   ```

2. **Use HTTPS**: Deploy behind a reverse proxy (nginx, Caddy)
   ```nginx
   location /telemetry/ {
       proxy_pass http://localhost:8501/;
       proxy_set_header Host $host;
       proxy_set_header X-Real-IP $remote_addr;
   }
   ```

3. **Restrict Access**: Bind to localhost only or use firewall rules
   ```bash
   streamlit run dashboard.py --server.address 127.0.0.1
   ```

4. **Read-Only Logs**: Mount log directory as read-only in Docker
   ```yaml
   volumes:
     - openclaw-logs:/tmp/openclaw:ro  # :ro = read-only
   ```

### Sensitive Data

Session logs may contain:
- User prompts and responses
- API keys (in tool call parameters)
- File paths and content
- System information

**Recommendations**:
- Keep logs in encrypted volumes
- Restrict dashboard access to authorized users
- Rotate logs regularly
- Consider redacting sensitive data in logs

## ğŸ› Troubleshooting

### "No session data found"

**Cause**: Dashboard can't find OpenClaw logs

**Solution**:
1. Check OpenClaw is running and generating logs
2. Verify log directory: `ls /tmp/openclaw/`
3. Use sidebar to select correct log directory
4. Check file permissions (dashboard needs read access)

### Dashboard is slow

**Cause**: Too many large log files

**Solutions**:
- Archive old logs: `mv /tmp/openclaw/*.log.old /archive/`
- Limit date range in the dashboard
- Use database storage (future feature)

### Missing metrics

**Cause**: BMasterAI integration not available

**Solutions**:
- Basic metrics work without BMasterAI
- For advanced metrics, install: `pip install bmasterai>=0.2.3`
- Some features require OpenClaw with telemetry enabled

## ğŸ“š Additional Resources

- **QUICKSTART.md**: 5-minute setup guide
- **Source**: Based on [bmasterai/openclaw-telemetry](https://github.com/travis-burmaster/bmasterai/tree/main/examples/openclaw-telemetry)
- **OpenClaw Docs**: https://docs.openclaw.ai
- **Support**: GitHub Issues or community Discord

## ğŸ¤ Contributing

Found a bug? Want a new feature?

1. Open an issue on GitHub
2. Submit a pull request
3. Join the discussion

See `CONTRIBUTING.md` for contribution guidelines.

## ğŸ“„ License

MIT License - see LICENSE file for details

---

**Built with â¤ï¸ for the OpenClaw community**  
**Part of the AgentBox project**
